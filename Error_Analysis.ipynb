{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEgeNbSa_xvU",
        "outputId": "e27a0329-7f30-4805-91fb-3b4591c27ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw41-3ON_xy4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import path\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input,Dense,LSTM,Flatten,Dropout,concatenate,Conv1D,MaxPooling2D,Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras import initializers, regularizers\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import keras_tuner\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import imgaug.augmenters as iaa\n",
        "from tensorflow.keras.preprocessing import image, text, sequence\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUldIKiacB-l"
      },
      "source": [
        "## 1. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pe8-5Nx5aVSW"
      },
      "outputs": [],
      "source": [
        "#  Reaearch Paper Link: https://arxiv.org/pdf/1505.00468.pdf\n",
        "\n",
        "def accuracy_metric(X,Y,encoded_features,model):\n",
        "\n",
        "  predicted_Y = model.predict(encoded_features,verbose=0)\n",
        "  predicted_class = tf.argmax(predicted_Y, axis=1, output_type=tf.int32)\n",
        "  predicted_ans = labelencoder.inverse_transform(predicted_class)\n",
        "\n",
        "  acc_val_lst = []\n",
        "  for i in tqdm(range(len(Y))):\n",
        "    acc_val = 0.0\n",
        "    temp = 0\n",
        "\n",
        "    for actual_ans in (list(X['answers'])[i]).split(\",\"):\n",
        "      if actual_ans == predicted_ans[i]:\n",
        "        temp += 1\n",
        "\n",
        "    if temp >= 3:\n",
        "      acc_val = 1\n",
        "    else:\n",
        "      acc_val = float(temp)/3\n",
        "\n",
        "    acc_val_lst.append(acc_val)\n",
        "\n",
        "  return (sum(acc_val_lst)/len(Y))*100, acc_val_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "QROBCp_aaT6K",
        "outputId": "45a8fe91-4e87-440f-bf1d-602c4514eb58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pickle' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ae1dc49fb34c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcolab_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Applied AI/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Applied AI/CS2/model/test_image_50k_0711.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer_50k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Applied AI/CS2/model/tokenizer_50k.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Applied AI/CS2/model/model_2lstm_vgg19_50k_1011_50.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabelencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Applied AI/CS2/model/labelencoder.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ],
      "source": [
        "colab_path = \"/content/drive/MyDrive/Applied AI/\"\n",
        "test_image= pickle.load(open('/content/drive/MyDrive/Applied AI/CS2/model/test_image_50k_0711.pkl', 'rb'))\n",
        "tokenizer_50k = pickle.load(open('/content/drive/MyDrive/Applied AI/CS2/model/tokenizer_50k.pkl', 'rb'))\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Applied AI/CS2/model/model_2lstm_vgg19_50k_1011_50.h5')\n",
        "labelencoder = pickle.load(open('/content/drive/MyDrive/Applied AI/CS2/model/labelencoder.pkl', 'rb'))\n",
        "\n",
        "test_sequences = tokenizer_50k.texts_to_sequences(list(X_test['question_preprocessed']))\n",
        "test_que = pad_sequences(test_sequences, maxlen=22, padding='post')\n",
        "print(test_image.shape, test_que.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B7Ajw2AaVVv"
      },
      "outputs": [],
      "source": [
        "Test_accuracy, accuracy_lst = accuracy_metric(X_test,Y_test,[test_que,test_image],model)\n",
        "print(\"\\nTest Accuracy:\",round(Test_accuracy,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiyEKTpOKfUv"
      },
      "outputs": [],
      "source": [
        "test_df = X_test\n",
        "test_df['answer'] = list(labelencoder.inverse_transform(list(y_test)))\n",
        "test_df['class_label'] = list(y_test)\n",
        "test_df['Accuracy'] = list(accuracy_lst)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08f-Rmq_Ljt1"
      },
      "outputs": [],
      "source": [
        "set(test_df['Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaUnEvhxf_xX"
      },
      "outputs": [],
      "source": [
        "print(f\"Only {len(test_df[(test_df.Accuracy != 0) & (test_df.Accuracy != 1)])} datapoints have accuracy 0.33 or 0.66, so add them with correct datapoints.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9FLB9vDI09i"
      },
      "outputs": [],
      "source": [
        "correct_df = test_df[test_df.Accuracy != 0]\n",
        "incorrect_df = test_df[test_df.Accuracy == 0]\n",
        "print(\"Number of Datapoints in correct_df:\",len(correct_df))\n",
        "print(\"Number of Datapoints in incorrect_df:\",len(incorrect_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-WoIn7mcmnD"
      },
      "outputs": [],
      "source": [
        "def top_20_firstword_que(data_f):\n",
        "  first_word = pd.Series(list(data_f['question_preprocessed'])).apply(lambda x: x.split()[0])\n",
        "  data_f[\"que_word\"] = list(first_word)\n",
        "  df = pd.DataFrame((data_f.groupby(['que_word']).count()).index,columns=[\"que_word\"])\n",
        "  df[\"que_count\"] = list(data_f.groupby(['que_word']).count()['question_preprocessed'])\n",
        "  df[\"que%\"] = round(df[\"que_count\"]/len(correct_df)*100,2)\n",
        "  df = df.sort_values(by='que_count',ascending=False)\n",
        "  return [tuple(x) for x in df.values[:20]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX9ZfXXUSho_"
      },
      "outputs": [],
      "source": [
        "def top_20_ans(data_f):\n",
        "  df = pd.DataFrame((data_f.groupby(['answer']).count()).index,columns=[\"answer\"])\n",
        "  df[\"answer_count\"] = list(data_f.groupby(['answer']).count()['answers'])\n",
        "  df[\"answer%\"] = round(df[\"answer_count\"]/len(correct_df)*100,2)\n",
        "  df = df.sort_values(by='answer_count',ascending=False)\n",
        "  return [tuple(x) for x in df.values[:20]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV3RrMq6mTLP"
      },
      "source": [
        "### 1.1 Correct Predicted Datapoints Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PFc6o3qcCIu"
      },
      "outputs": [],
      "source": [
        "top_20_firstword_que(correct_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giTNb_ZmUOUg"
      },
      "outputs": [],
      "source": [
        "top_20_ans(correct_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVwgCR9KmZ5A"
      },
      "source": [
        "### 1.2 Incorrect Predicted Datapoints Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeH1jKxpc23j"
      },
      "outputs": [],
      "source": [
        "top_20_firstword_que(incorrect_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlY6iUVwMBax"
      },
      "outputs": [],
      "source": [
        "top_20_ans(incorrect_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPD09qaRzbX3"
      },
      "source": [
        "### 1.3 Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYowHKpvv-no"
      },
      "source": [
        "* In Correctly predicted datapoints, most questions start with the 'is' word and in Incorrectly predicted datapoints, most questions start with the 'what' word.\n",
        "* In Correctly predicted datapoints, approx 60% of questions have 'yes' or 'no' answers.\n",
        "* In Incorrectly predicted datapoints, only 20% of questions have 'yes' or 'no' answers and most questions have numeric, color, and other types of answers.\n",
        "* From this Error analysis, we can conclude that questions that have 'yes' or 'no' answer types are mostly correctly predicted and questions that have numeric or other answer types are a little bit difficult to predict."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Uqyq7HR9pooe",
        "dvKl4uNhpooe",
        "83pNne4K1oqy",
        "cGuPG0XPOuNj",
        "1QihwmxgOuNk",
        "EpuhK7pj7H65",
        "nUldIKiacB-l",
        "rV3RrMq6mTLP",
        "wVwgCR9KmZ5A",
        "iPD09qaRzbX3",
        "u5guJXfNeZN6"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}